{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.2\n",
      "Num GPUs Available:  2\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "use_gpu = True\n",
    "if use_gpu:\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\";\n",
    "    # The GPU id to use, usually either \"0\" or \"1\";\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from nltk import tokenize\n",
    "\n",
    "from han.model import HAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_br(s):\n",
    "    s = re.sub('<br\\s?\\/>|</{0,1}br>', \" . \", s)\n",
    "    s = re.sub(' *\\.[ \\.]*', \". \", s)\n",
    "    return s\n",
    "\n",
    "def attention2color(attention_score):\n",
    "    r = 255 - int(attention_score * 255)\n",
    "    color = rgb_to_hex((255, r, r))\n",
    "    return str(color)\n",
    "\n",
    "def rgb_to_hex(rgb):\n",
    "    return '#%02x%02x%02x' % rgb\n",
    "\n",
    "def visualize_attention_line(attentions_text, decoded_text, show=True, normalize=True, color_paragraph=0):\n",
    "    token_attention_dic = {}\n",
    "    if normalize:\n",
    "        attentions_text = (attentions_text - np.min(attentions_text)) / (np.max(attentions_text) - np.min(attentions_text))\n",
    "    for token, attention_score in zip(decoded_text, attentions_text):\n",
    "        #print(token, attention_score)\n",
    "        token_attention_dic[token] = attention_score\n",
    "\n",
    "    # Build HTML String to viualize attentions\n",
    "    html_text = \"<div style='font-size: large;border-left-width:10px;border-left-style: solid; border-left-color: {}'>\".format(attention2color(color_paragraph))\n",
    "    for token, attention in token_attention_dic.items():\n",
    "        html_text += \"<span style='background-color:{};'>{} <span> \".format(attention2color(attention), token)\n",
    "    html_text += \"</div><br>\"\n",
    "\n",
    "    # Display text enriched with attention scores\n",
    "    if show:\n",
    "        display(HTML(html_text))\n",
    "    else:\n",
    "        return html_text\n",
    "\n",
    "def visualize_attention(word_att, sent_att, sent_tokenized_review, label_probs):\n",
    "\n",
    "    # Display Truth and classification \n",
    "    html_text = \"<p style='font-size: large'><b>Classified as:</b> \"\n",
    "    html_text += max(label_probs, key=label_probs.get)\n",
    "    html_text += \"</p>\"\n",
    "    \n",
    "    display(HTML(html_text))\n",
    "    \n",
    "    # PLOT EMOTION SCORES\n",
    "    plt.figure(figsize=(5,2))\n",
    "    plt.bar(np.arange(len(labels)), label_probs.values(), align='center', alpha=0.5, color=['blue', 'red', 'green', 'black', 'cyan', \"purple\"])\n",
    "    plt.xticks(np.arange(len(labels)), label_probs.keys())\n",
    "    plt.ylabel('Scores')\n",
    "    plt.show()\n",
    "    \n",
    "    sent_att = sent_att.squeeze()\n",
    "    attentions_sent = (sent_att - np.min(sent_att)) / (np.max(sent_att) - np.min(sent_att))\n",
    "\n",
    "    for i, att in enumerate(sent_att):\n",
    "        word_att[i] *= att\n",
    "    word_att = (word_att - np.min(word_att)) / (np.max(word_att) - np.min(word_att))\n",
    "    \n",
    "    res = han.word_att_to_df(sent_tokenized_review, word_att)\n",
    "    res['sentence_att'] = pd.Series(sent_att.squeeze())\n",
    "\n",
    "    # Build HTML String to viualize attentions\n",
    "    html_text = \"<hr><p style='font-size: large'><b>Text:</b></p>\"\n",
    "    \n",
    "    for i, att in enumerate(attentions_sent):\n",
    "        decoded_text = res['word_att'][i].keys()\n",
    "        attentions_text = res['word_att'][i].values()\n",
    "        \n",
    "        html_text += visualize_attention_line(attentions_text, decoded_text, \n",
    "                                          show=False, normalize=False, color_paragraph=att)\n",
    "    # Display text enriched with attention scores \n",
    "    display(HTML(html_text))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>type</th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>Once again Mr. Costner has dragged out a movie...</td>\n",
       "      <td>neg</td>\n",
       "      <td>0_2.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>This is an example of why the majority of acti...</td>\n",
       "      <td>neg</td>\n",
       "      <td>10000_4.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "      <td>First of all I hate those moronic rappers, who...</td>\n",
       "      <td>neg</td>\n",
       "      <td>10001_1.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>test</td>\n",
       "      <td>Not even the Beatles could write songs everyon...</td>\n",
       "      <td>neg</td>\n",
       "      <td>10002_3.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>test</td>\n",
       "      <td>Brass pictures (movies is not a fitting word f...</td>\n",
       "      <td>neg</td>\n",
       "      <td>10003_3.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  type                                             review label  \\\n",
       "0           0  test  Once again Mr. Costner has dragged out a movie...   neg   \n",
       "1           1  test  This is an example of why the majority of acti...   neg   \n",
       "2           2  test  First of all I hate those moronic rappers, who...   neg   \n",
       "3           3  test  Not even the Beatles could write songs everyon...   neg   \n",
       "4           4  test  Brass pictures (movies is not a fitting word f...   neg   \n",
       "\n",
       "          file  \n",
       "0      0_2.txt  \n",
       "1  10000_4.txt  \n",
       "2  10001_1.txt  \n",
       "3  10002_3.txt  \n",
       "4  10003_3.txt  "
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing the dataset\n",
    "\n",
    "dataset = pd.read_csv('../IMDB Review - LSTM with Attention/imdb_master.csv', encoding = \"ISO-8859-1\")\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.drop(['Unnamed: 0', 'file'], axis = 1)\n",
    "dataset = dataset[dataset.label != 'unsup']\n",
    "dataset['label'] = dataset['label'].map({'pos': 1, 'neg': 0})\n",
    "dataset['review'] = dataset['review'].apply(clean_br)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = []\n",
    "reviews = []\n",
    "labels = []\n",
    "for idx in dataset.index:\n",
    "    texts.append(dataset.review[idx])\n",
    "    sentences = tokenize.sent_tokenize(dataset.review[idx])\n",
    "    reviews.append(sentences)\n",
    "    labels.append(dataset.label[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_FEATURES = 120000 # how many unique words to use (i.e num rows in embedding vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=MAX_FEATURES)\n",
    "tokenizer.fit_on_texts(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 100 # Maximum length for texts\n",
    "MAX_SENT = 20\n",
    "\n",
    "data = np.zeros((len(texts), MAX_SENT, MAX_LEN), dtype='int32')\n",
    "\n",
    "for i, sentences in enumerate(reviews):\n",
    "    for j, sent in enumerate(sentences):\n",
    "        if j < MAX_SENT:\n",
    "            wordTokens = text_to_word_sequence(sent)\n",
    "            k = 0\n",
    "            for _, word in enumerate(wordTokens):\n",
    "                try:\n",
    "                    if k < MAX_LEN and tokenizer.word_index[word] < MAX_FEATURES:\n",
    "                        data[i, j, k] = tokenizer.word_index[word]\n",
    "                        k = k + 1\n",
    "                except:\n",
    "                    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 123681 unique tokens.\n",
      "Shape of reviews (data) tensor: (50000, 20, 100)\n",
      "Shape of sentiment (label) tensor: (50000, 2)\n"
     ]
    }
   ],
   "source": [
    "word_index = tokenizer.word_index\n",
    "print('Total %s unique tokens.' % len(word_index))\n",
    "\n",
    "labels = to_categorical(np.asarray(labels))\n",
    "print('Shape of reviews (data) tensor:', data.shape)\n",
    "print('Shape of sentiment (label) tensor:', labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_split = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive and negative reviews in training and validation set\n",
      "[19993. 20007.]\n",
      "[5007. 4993.]\n"
     ]
    }
   ],
   "source": [
    "indices = np.arange(data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "data = data[indices]\n",
    "labels = labels[indices]\n",
    "nb_validation_samples = int(validation_split * data.shape[0])\n",
    "\n",
    "x_train = data[:-nb_validation_samples]\n",
    "y_train = labels[:-nb_validation_samples]\n",
    "x_val = data[-nb_validation_samples:]\n",
    "y_val = labels[-nb_validation_samples:]\n",
    "\n",
    "print('Number of positive and negative reviews in training and validation set')\n",
    "print(y_train.sum(axis=0))\n",
    "print(y_val.sum(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(123682, 300)"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_dir = '../BIGRU-Attention_visualized/glove.840B.300d/'\n",
    "EMBEDDING_FILE = 'glove.840B.300d.txt'\n",
    "EMB_SIZE = 300\n",
    "\n",
    "# Reading file\n",
    "embeddings_index = {}\n",
    "f = open(os.path.join(glove_dir, EMBEDDING_FILE))\n",
    "for line in f:\n",
    "    try:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "    except:\n",
    "        pass\n",
    "f.close()\n",
    "\n",
    "# Embedding matrix creation\n",
    "embedding_matrix = np.random.random((len(word_index) + 1, EMB_SIZE))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HAN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Level\n",
      "Model: \"model_44\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_14 (InputLayer)        [(None, 100)]             0         \n",
      "_________________________________________________________________\n",
      "embedding_6 (Embedding)      (None, 100, 300)          37104600  \n",
      "_________________________________________________________________\n",
      "bidirectional_12 (Bidirectio (None, 100, 100)          105600    \n",
      "_________________________________________________________________\n",
      "time_distributed_18 (TimeDis (None, 100, 100)          10100     \n",
      "_________________________________________________________________\n",
      "word_attention (Attention)   (None, 100)               10200     \n",
      "=================================================================\n",
      "Total params: 37,230,500\n",
      "Trainable params: 125,900\n",
      "Non-trainable params: 37,104,600\n",
      "_________________________________________________________________\n",
      "Sentence Level\n",
      "Model: \"model_45\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_13 (InputLayer)        [(None, 20, 100)]         0         \n",
      "_________________________________________________________________\n",
      "time_distributed_19 (TimeDis (None, 20, 100)           37230500  \n",
      "_________________________________________________________________\n",
      "bidirectional_13 (Bidirectio (None, 20, 100)           45600     \n",
      "_________________________________________________________________\n",
      "time_distributed_20 (TimeDis (None, 20, 100)           10100     \n",
      "_________________________________________________________________\n",
      "sent_attention (Attention)   (None, 100)               10200     \n",
      "_________________________________________________________________\n",
      "classification (Dense)       (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 37,296,602\n",
      "Trainable params: 192,002\n",
      "Non-trainable params: 37,104,600\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Initialization\n",
    "han = HAN(embedding_matrix, \n",
    "          max_sent_length=MAX_LEN, \n",
    "          max_sent_num=MAX_SENT, \n",
    "          word_embed_dim=100, \n",
    "          sent_embed_dim=100)\n",
    "han.print_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 0.4926 - acc: 0.7438\n",
      "Epoch 00001: val_loss improved from inf to 0.33508, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "2000/2000 [==============================] - 152s 76ms/step - loss: 0.4926 - acc: 0.7438 - val_loss: 0.3351 - val_acc: 0.8564\n",
      "Epoch 2/10\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 0.3162 - acc: 0.8655\n",
      "Epoch 00002: val_loss improved from 0.33508 to 0.31072, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "2000/2000 [==============================] - 153s 76ms/step - loss: 0.3162 - acc: 0.8655 - val_loss: 0.3107 - val_acc: 0.8673\n",
      "Epoch 3/10\n",
      "1999/2000 [============================>.] - ETA: 0s - loss: 0.2986 - acc: 0.8750\n",
      "Epoch 00003: val_loss improved from 0.31072 to 0.30044, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "2000/2000 [==============================] - 150s 75ms/step - loss: 0.2987 - acc: 0.8750 - val_loss: 0.3004 - val_acc: 0.8733\n",
      "Epoch 4/10\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 0.2885 - acc: 0.8797\n",
      "Epoch 00004: val_loss improved from 0.30044 to 0.29194, saving model to ./\n",
      "INFO:tensorflow:Assets written to: ./assets\n",
      "2000/2000 [==============================] - 151s 75ms/step - loss: 0.2885 - acc: 0.8797 - val_loss: 0.2919 - val_acc: 0.8764\n",
      "Epoch 5/10\n",
      " 137/2000 [=>............................] - ETA: 1:36 - loss: 0.2850 - acc: 0.8785"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-247-7a12647c40db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcheckpoint_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mhan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/attention/interpretable-han-for-document-classification-with-keras/han/model.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self, checkpoint_path, X_train, y_train, X_test, y_test, optimizer, loss, metric, monitor, batch_size, epochs)\u001b[0m\n\u001b[1;32m    141\u001b[0m         )\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m         self.model.fit(\n\u001b[0m\u001b[1;32m    144\u001b[0m             \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/myenv_38/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/myenv_38/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    853\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m         \u001b[0mepoch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/myenv_38/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    387\u001b[0m     \"\"\"\n\u001b[1;32m    388\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/myenv_38/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_process_logs\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;34m\"\"\"Turns tensors into numpy arrays or Python scalars.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/myenv_38/lib/python3.8/site-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36mto_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 523\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/myenv_38/lib/python3.8/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 617\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/myenv_38/lib/python3.8/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 617\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/myenv_38/lib/python3.8/site-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    517\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    520\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/myenv_38/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    959\u001b[0m     \"\"\"\n\u001b[1;32m    960\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 961\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    962\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/myenv_38/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    925\u001b[0m     \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 927\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    928\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training\n",
    "checkpoint_path = './'\n",
    "han.train_model(checkpoint_path, x_train, y_train, x_val, y_val, \n",
    "                batch_size=20, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction and explaination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Truth :  1.0\n",
      "Pred :  0.97705984\n"
     ]
    }
   ],
   "source": [
    "line=4\n",
    "\n",
    "# Prediction\n",
    "X = x_val[line:line+1]\n",
    "truth = y_val[line]\n",
    "pred = han.model.predict(X)[0]\n",
    "print(\"Truth : \", truth[1])\n",
    "print(\"Pred : \", pred[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (lambda_47), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'sent_attention_6/W:0' shape=(100, 100) dtype=float32>\n",
      "  <tf.Variable 'sent_attention_6/bias:0' shape=(100,) dtype=float32>\n",
      "  <tf.Variable 'sent_attention_6/context_vector:0' shape=(100,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>stephen sondheim's sweeney todd the demon barb...</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>although it swept virtually every award imagin...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fortunately however the play then went on tour...</td>\n",
       "      <td>4.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the result is a remarkable capture of the play...</td>\n",
       "      <td>5.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>there is however a flaw</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>simply stated stage plays do not film very wel...</td>\n",
       "      <td>6.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sweeney todd is no exception</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>seen on film it has a stand and sing quality a...</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>taking this stage play on film effect into con...</td>\n",
       "      <td>15.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>lansbury is astonishing a mixture of silliness...</td>\n",
       "      <td>11.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>the overall cast is quite fine and although th...</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>and the music</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>who can argue with what most consider sondheim...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>the story itself is extremely well known parti...</td>\n",
       "      <td>8.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>in 1846 thomas peckett prest cobbled together ...</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>each one however was more or less the same swe...</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>the sondheim version is specifically based on ...</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>the story is very grand guignol with a lot of ...</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>sondheim's lyrics are often ironic but never m...</td>\n",
       "      <td>5.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>like the concert version starring hern and pat...</td>\n",
       "      <td>7.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    0     1\n",
       "0   stephen sondheim's sweeney todd the demon barb...   1.2\n",
       "1   although it swept virtually every award imagin...   5.0\n",
       "2   fortunately however the play then went on tour...   4.7\n",
       "3   the result is a remarkable capture of the play...   5.8\n",
       "4                             there is however a flaw   3.5\n",
       "5   simply stated stage plays do not film very wel...   6.3\n",
       "6                        sweeney todd is no exception   1.3\n",
       "7   seen on film it has a stand and sing quality a...   7.0\n",
       "8   taking this stage play on film effect into con...  15.8\n",
       "9   lansbury is astonishing a mixture of silliness...  11.3\n",
       "10  the overall cast is quite fine and although th...   7.0\n",
       "11                                      and the music   0.5\n",
       "12  who can argue with what most consider sondheim...   1.0\n",
       "13  the story itself is extremely well known parti...   8.8\n",
       "14  in 1846 thomas peckett prest cobbled together ...   1.7\n",
       "15  each one however was more or less the same swe...   1.1\n",
       "16  the sondheim version is specifically based on ...   1.6\n",
       "17  the story is very grand guignol with a lot of ...   3.8\n",
       "18  sondheim's lyrics are often ironic but never m...   5.4\n",
       "19  like the concert version starring hern and pat...   7.2"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explaiantion by sentence\n",
    "sent_att = han.show_sent_attention(X)\n",
    "sent_tokenized_reviews = [tokenizer.sequences_to_texts(X[0])]\n",
    "res = han.sent_att_to_df(sent_tokenized_reviews, sent_att)\n",
    "z = {}\n",
    "for el in res['sent_att'][0]:\n",
    "    z = {**z, **el}\n",
    "df = pd.DataFrame(z.items())\n",
    "df.iloc[:, 1] = round(df.iloc[:, 1]*100, 1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (lambda_48), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'word_attention_6/W:0' shape=(100, 100) dtype=float32>\n",
      "  <tf.Variable 'word_attention_6/bias:0' shape=(100,) dtype=float32>\n",
      "  <tf.Variable 'word_attention_6/context_vector:0' shape=(100,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_att</th>\n",
       "      <th>review</th>\n",
       "      <th>sentence_att</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'stephen': 0.05987169, 'sondheim's': 0.006701...</td>\n",
       "      <td>[stephen, sondheim's, sweeney, todd, the, demo...</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'although': 0.0492706, 'it': 0.06542231, 'swe...</td>\n",
       "      <td>[although, it, swept, virtually, every, award,...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'fortunately': 0.3227381, 'however': 0.187590...</td>\n",
       "      <td>[fortunately, however, the, play, then, went, ...</td>\n",
       "      <td>4.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'the': 0.008776995, 'result': 0.064711675, 'i...</td>\n",
       "      <td>[the, result, is, a, remarkable, capture, of, ...</td>\n",
       "      <td>5.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'there': 0.03423464, 'is': 0.090707935, 'howe...</td>\n",
       "      <td>[there, is, however, a, flaw]</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'simply': 0.02613682, 'stated': 0.014920265, ...</td>\n",
       "      <td>[simply, stated, stage, plays, do, not, film, ...</td>\n",
       "      <td>6.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'sweeney': 0.09134657, 'todd': 0.05076817, 'i...</td>\n",
       "      <td>[sweeney, todd, is, no, exception]</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'seen': 0.010975278, 'on': 0.0054082233, 'fil...</td>\n",
       "      <td>[seen, on, film, it, has, a, stand, and, sing,...</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'taking': 0.008173524, 'this': 0.018405082, '...</td>\n",
       "      <td>[taking, this, stage, play, on, film, effect, ...</td>\n",
       "      <td>15.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'lansbury': 0.03321199, 'is': 0.028896136, 'a...</td>\n",
       "      <td>[lansbury, is, astonishing, a, mixture, of, si...</td>\n",
       "      <td>11.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>{'the': 0.0041289153, 'overall': 0.071936265, ...</td>\n",
       "      <td>[the, overall, cast, is, quite, fine, and, alt...</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>{'and': 0.27524447, 'the': 0.20929986, 'music'...</td>\n",
       "      <td>[and, the, music]</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>{'who': 0.058644183, 'can': 0.07374425, 'argue...</td>\n",
       "      <td>[who, can, argue, with, what, most, consider, ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>{'the': 0.012575046, 'story': 0.021075333, 'it...</td>\n",
       "      <td>[the, story, itself, is, extremely, well, know...</td>\n",
       "      <td>8.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>{'in': 0.005862284, '1846': 0.008506671, 'thom...</td>\n",
       "      <td>[in, 1846, thomas, peckett, prest, cobbled, to...</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>{'each': 0.017874435, 'one': 0.034648247, 'how...</td>\n",
       "      <td>[each, one, however, was, more, or, less, the,...</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>{'the': 0.058087107, 'sondheim': 0.075995445, ...</td>\n",
       "      <td>[the, sondheim, version, is, specifically, bas...</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>{'the': 0.004317021, 'story': 0.012152399, 'is...</td>\n",
       "      <td>[the, story, is, very, grand, guignol, with, a...</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>{'sondheim's': 0.00082106056, 'lyrics': 0.0027...</td>\n",
       "      <td>[sondheim's, lyrics, are, often, ironic, but, ...</td>\n",
       "      <td>5.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>{'like': 0.017524876, 'the': 0.011835353, 'con...</td>\n",
       "      <td>[like, the, concert, version, starring, hern, ...</td>\n",
       "      <td>7.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             word_att  \\\n",
       "0   {'stephen': 0.05987169, 'sondheim's': 0.006701...   \n",
       "1   {'although': 0.0492706, 'it': 0.06542231, 'swe...   \n",
       "2   {'fortunately': 0.3227381, 'however': 0.187590...   \n",
       "3   {'the': 0.008776995, 'result': 0.064711675, 'i...   \n",
       "4   {'there': 0.03423464, 'is': 0.090707935, 'howe...   \n",
       "5   {'simply': 0.02613682, 'stated': 0.014920265, ...   \n",
       "6   {'sweeney': 0.09134657, 'todd': 0.05076817, 'i...   \n",
       "7   {'seen': 0.010975278, 'on': 0.0054082233, 'fil...   \n",
       "8   {'taking': 0.008173524, 'this': 0.018405082, '...   \n",
       "9   {'lansbury': 0.03321199, 'is': 0.028896136, 'a...   \n",
       "10  {'the': 0.0041289153, 'overall': 0.071936265, ...   \n",
       "11  {'and': 0.27524447, 'the': 0.20929986, 'music'...   \n",
       "12  {'who': 0.058644183, 'can': 0.07374425, 'argue...   \n",
       "13  {'the': 0.012575046, 'story': 0.021075333, 'it...   \n",
       "14  {'in': 0.005862284, '1846': 0.008506671, 'thom...   \n",
       "15  {'each': 0.017874435, 'one': 0.034648247, 'how...   \n",
       "16  {'the': 0.058087107, 'sondheim': 0.075995445, ...   \n",
       "17  {'the': 0.004317021, 'story': 0.012152399, 'is...   \n",
       "18  {'sondheim's': 0.00082106056, 'lyrics': 0.0027...   \n",
       "19  {'like': 0.017524876, 'the': 0.011835353, 'con...   \n",
       "\n",
       "                                               review  sentence_att  \n",
       "0   [stephen, sondheim's, sweeney, todd, the, demo...           1.2  \n",
       "1   [although, it, swept, virtually, every, award,...           5.0  \n",
       "2   [fortunately, however, the, play, then, went, ...           4.7  \n",
       "3   [the, result, is, a, remarkable, capture, of, ...           5.8  \n",
       "4                       [there, is, however, a, flaw]           3.5  \n",
       "5   [simply, stated, stage, plays, do, not, film, ...           6.3  \n",
       "6                  [sweeney, todd, is, no, exception]           1.3  \n",
       "7   [seen, on, film, it, has, a, stand, and, sing,...           7.0  \n",
       "8   [taking, this, stage, play, on, film, effect, ...          15.8  \n",
       "9   [lansbury, is, astonishing, a, mixture, of, si...          11.3  \n",
       "10  [the, overall, cast, is, quite, fine, and, alt...           7.0  \n",
       "11                                  [and, the, music]           0.5  \n",
       "12  [who, can, argue, with, what, most, consider, ...           1.0  \n",
       "13  [the, story, itself, is, extremely, well, know...           8.8  \n",
       "14  [in, 1846, thomas, peckett, prest, cobbled, to...           1.7  \n",
       "15  [each, one, however, was, more, or, less, the,...           1.1  \n",
       "16  [the, sondheim, version, is, specifically, bas...           1.6  \n",
       "17  [the, story, is, very, grand, guignol, with, a...           3.8  \n",
       "18  [sondheim's, lyrics, are, often, ironic, but, ...           5.4  \n",
       "19  [like, the, concert, version, starring, hern, ...           7.2  "
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explaiantion by word\n",
    "X = x_val[line]\n",
    "word_att = han.show_word_attention(X)\n",
    "sent_tokenized_review = tokenizer.sequences_to_texts(X)\n",
    "\n",
    "res = han.word_att_to_df(sent_tokenized_review, word_att)\n",
    "res['sentence_att'] = round(pd.Series(sent_att.squeeze())*100,1)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style='font-size: large;border-left-width:10px;border-left-style: solid; border-left-color: #ffffff'><span style='background-color:#ffb7b7;'>although <span> <span style='background-color:#ff9a9a;'>it <span> <span style='background-color:#ff9e9e;'>swept <span> <span style='background-color:#ff3535;'>virtually <span> <span style='background-color:#ffa5a5;'>every <span> <span style='background-color:#ffd8d8;'>award <span> <span style='background-color:#ff0000;'>imaginable <span> <span style='background-color:#ffffff;'>the <span> <span style='background-color:#fffafa;'>box <span> <span style='background-color:#ffffff;'>office <span> <span style='background-color:#ffc0c0;'>fell <span> <span style='background-color:#ffe1e1;'>short <span> <span style='background-color:#fffefe;'>of <span> <span style='background-color:#ff9797;'>expectations <span> <span style='background-color:#fff5f5;'>and <span> <span style='background-color:#fffefe;'>original <span> <span style='background-color:#ffe4e4;'>production <span> <span style='background-color:#ffa3a3;'>ended <span> <span style='background-color:#ffbebe;'>its <span> <span style='background-color:#ffb9b9;'>run <span> <span style='background-color:#ffffff;'>at <span> <span style='background-color:#ffffff;'>557 <span> <span style='background-color:#ffd0d0;'>performances <span> </div><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>although</td>\n",
       "      <td>4.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>it</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>swept</td>\n",
       "      <td>6.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>virtually</td>\n",
       "      <td>12.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>every</td>\n",
       "      <td>5.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>award</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>imaginable</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>the</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>box</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>office</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>fell</td>\n",
       "      <td>4.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>short</td>\n",
       "      <td>2.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>of</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>expectations</td>\n",
       "      <td>6.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>and</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>original</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>production</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ended</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>its</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>run</td>\n",
       "      <td>4.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>at</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>557</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>performances</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0     1\n",
       "0       although   4.9\n",
       "1             it   6.5\n",
       "2          swept   6.3\n",
       "3      virtually  12.1\n",
       "4          every   5.9\n",
       "5          award   3.1\n",
       "6     imaginable  15.0\n",
       "7            the   0.9\n",
       "8            box   1.2\n",
       "9         office   0.9\n",
       "10          fell   4.4\n",
       "11         short   2.6\n",
       "12            of   1.0\n",
       "13  expectations   6.7\n",
       "14           and   1.5\n",
       "15      original   1.0\n",
       "16    production   2.4\n",
       "17         ended   6.0\n",
       "18           its   4.5\n",
       "19           run   4.8\n",
       "20            at   0.9\n",
       "21           557   0.9\n",
       "22  performances   3.5"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_nb = 1\n",
    "\n",
    "df = pd.DataFrame(res['word_att'][sent_nb].items())\n",
    "df.iloc[:, 1] = round(df.iloc[:, 1]*100, 1)\n",
    "\n",
    "decoded_text = df.iloc[:, 0].values\n",
    "attentions_text = df.iloc[:, 1].values\n",
    "visualize_attention_line(attentions_text, decoded_text)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p style='font-size: large'><b>Classified as:</b> positive</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<hr><p style='font-size: large'><b>Text:</b></p><div style='font-size: large;border-left-width:10px;border-left-style: solid; border-left-color: #fff4f4'><span style='background-color:#fffbfb;'>stephen <span> <span style='background-color:#ffffff;'>sondheim's <span> <span style='background-color:#fffefe;'>sweeney <span> <span style='background-color:#ffffff;'>todd <span> <span style='background-color:#fffcfc;'>the <span> <span style='background-color:#fffafa;'>demon <span> <span style='background-color:#fffdfd;'>barber <span> <span style='background-color:#fffdfd;'>of <span> <span style='background-color:#fffcfc;'>fleet <span> <span style='background-color:#fffefe;'>street <span> <span style='background-color:#fffdfd;'>opened <span> <span style='background-color:#fffefe;'>on <span> <span style='background-color:#fffefe;'>broadway <span> <span style='background-color:#fffefe;'>1 <span> <span style='background-color:#ffffff;'>march <span> <span style='background-color:#ffffff;'>1979 <span> <span style='background-color:#fffefe;'>with <span> <span style='background-color:#fffefe;'>len <span> <span style='background-color:#ffffff;'>cariou <span> <span style='background-color:#fffefe;'>and <span> <span style='background-color:#fffdfd;'>angela <span> <span style='background-color:#fff6f6;'>lansbury <span> <span style='background-color:#fffdfd;'>in <span> <span style='background-color:#fff7f7;'>leading <span> <span style='background-color:#fff8f8;'>roles <span> </div><br><div style='font-size: large;border-left-width:10px;border-left-style: solid; border-left-color: #ffb4b4'><span style='background-color:#ffefef;'>although <span> <span style='background-color:#ffe9e9;'>it <span> <span style='background-color:#ffeaea;'>swept <span> <span style='background-color:#ffd6d6;'>virtually <span> <span style='background-color:#ffecec;'>every <span> <span style='background-color:#fff5f5;'>award <span> <span style='background-color:#ffcdcd;'>imaginable <span> <span style='background-color:#fffdfd;'>the <span> <span style='background-color:#fffcfc;'>box <span> <span style='background-color:#fffdfd;'>office <span> <span style='background-color:#fff1f1;'>fell <span> <span style='background-color:#fff7f7;'>short <span> <span style='background-color:#fffcfc;'>of <span> <span style='background-color:#ffe9e9;'>expectations <span> <span style='background-color:#fffbfb;'>and <span> <span style='background-color:#fffcfc;'>original <span> <span style='background-color:#fff7f7;'>production <span> <span style='background-color:#ffebeb;'>ended <span> <span style='background-color:#fff0f0;'>its <span> <span style='background-color:#ffefef;'>run <span> <span style='background-color:#fffcfc;'>at <span> <span style='background-color:#fffcfc;'>557 <span> <span style='background-color:#fff4f4;'>performances <span> </div><br><div style='font-size: large;border-left-width:10px;border-left-style: solid; border-left-color: #ffbaba'><span style='background-color:#ff9a9a;'>fortunately <span> <span style='background-color:#ffc4c4;'>however <span> <span style='background-color:#fffcfc;'>the <span> <span style='background-color:#fff0f0;'>play <span> <span style='background-color:#fff3f3;'>then <span> <span style='background-color:#fff3f3;'>went <span> <span style='background-color:#fff8f8;'>on <span> <span style='background-color:#fffafa;'>tour <span> <span style='background-color:#fffbfb;'>and <span> <span style='background-color:#fffafa;'>along <span> <span style='background-color:#fff8f8;'>way <span> <span style='background-color:#ffefef;'>was <span> <span style='background-color:#fff5f5;'>captured <span> <span style='background-color:#ffe5e5;'>film <span> </div><br><div style='font-size: large;border-left-width:10px;border-left-style: solid; border-left-color: #ffa7a7'><span style='background-color:#fffcfc;'>the <span> <span style='background-color:#ffe6e6;'>result <span> <span style='background-color:#ffe0e0;'>is <span> <span style='background-color:#fffafa;'>a <span> <span style='background-color:#ff8484;'>remarkable <span> <span style='background-color:#ffdada;'>capture <span> <span style='background-color:#fffbfb;'>of <span> <span style='background-color:#fff5f5;'>play <span> <span style='background-color:#fff9f9;'>featuring <span> <span style='background-color:#fff9f9;'>george <span> <span style='background-color:#fff8f8;'>hern <span> <span style='background-color:#fffafa;'>who <span> <span style='background-color:#fff6f6;'>replaced <span> <span style='background-color:#fffefe;'>cariou <span> <span style='background-color:#fffcfc;'>and <span> <span style='background-color:#fff3f3;'>lansbury <span> <span style='background-color:#fffcfc;'>in <span> <span style='background-color:#fff3f3;'>close <span> <span style='background-color:#fff1f1;'>approximation <span> <span style='background-color:#fffbfb;'>original <span> <span style='background-color:#fffcfc;'>broadway <span> <span style='background-color:#fff9f9;'>staging <span> </div><br><div style='font-size: large;border-left-width:10px;border-left-style: solid; border-left-color: #ffcece'><span style='background-color:#fff8f8;'>there <span> <span style='background-color:#ffeaea;'>is <span> <span style='background-color:#ffd0d0;'>however <span> <span style='background-color:#ffe7e7;'>a <span> <span style='background-color:#ff8383;'>flaw <span> </div><br><div style='font-size: large;border-left-width:10px;border-left-style: solid; border-left-color: #ff9f9f'><span style='background-color:#fff4f4;'>simply <span> <span style='background-color:#fff9f9;'>stated <span> <span style='background-color:#fffdfd;'>stage <span> <span style='background-color:#fffafa;'>plays <span> <span style='background-color:#fffdfd;'>do <span> <span style='background-color:#fffcfc;'>not <span> <span style='background-color:#fff4f4;'>film <span> <span style='background-color:#ffdddd;'>very <span> <span style='background-color:#fff8f8;'>well <span> <span style='background-color:#fffafa;'>for <span> <span style='background-color:#fffafa;'>a <span> <span style='background-color:#ffefef;'>performance <span> <span style='background-color:#fff8f8;'>that <span> <span style='background-color:#fff9f9;'>works <span> <span style='background-color:#fffdfd;'>on <span> <span style='background-color:#fffefe;'>the <span> <span style='background-color:#fffdfd;'>must <span> <span style='background-color:#fffdfd;'>fill <span> <span style='background-color:#ffffff;'>theatre <span> <span style='background-color:#fffbfb;'>and <span> <span style='background-color:#fffafa;'>is <span> <span style='background-color:#fff6f6;'>therefore <span> <span style='background-color:#fff6f6;'>large <span> <span style='background-color:#fffafa;'>when <span> <span style='background-color:#fffafa;'>placed <span> <span style='background-color:#fff7f7;'>such <span> <span style='background-color:#ffefef;'>performances <span> <span style='background-color:#ffeded;'>often <span> <span style='background-color:#ffe8e8;'>seem <span> <span style='background-color:#ffe5e5;'>slightly <span> <span style='background-color:#ffe6e6;'>static <span> <span style='background-color:#ffdede;'>oppressively <span> <span style='background-color:#fff0f0;'>aggressive <span> <span style='background-color:#fffdfd;'>or <span> <span style='background-color:#fffcfc;'>both <span> </div><br><div style='font-size: large;border-left-width:10px;border-left-style: solid; border-left-color: #fff2f2'><span style='background-color:#fff8f8;'>sweeney <span> <span style='background-color:#fffbfb;'>todd <span> <span style='background-color:#ffebeb;'>is <span> <span style='background-color:#fff5f5;'>no <span> <span style='background-color:#ffdede;'>exception <span> </div><br><div style='font-size: large;border-left-width:10px;border-left-style: solid; border-left-color: #ff9494'><span style='background-color:#fffafa;'>seen <span> <span style='background-color:#fffdfd;'>on <span> <span style='background-color:#fff6f6;'>film <span> <span style='background-color:#fff5f5;'>it <span> <span style='background-color:#fff5f5;'>has <span> <span style='background-color:#fff9f9;'>a <span> <span style='background-color:#fff7f7;'>stand <span> <span style='background-color:#fff8f8;'>and <span> <span style='background-color:#fffbfb;'>sing <span> <span style='background-color:#fff4f4;'>quality <span> <span style='background-color:#fff9f9;'>while <span> <span style='background-color:#fff7f7;'>both <span> <span style='background-color:#fffafa;'>hern <span> <span style='background-color:#fff3f3;'>lansbury <span> <span style='background-color:#fff4f4;'>seem <span> <span style='background-color:#fffefe;'>to <span> <span style='background-color:#fffefe;'>have <span> <span style='background-color:#fffefe;'>modulated <span> <span style='background-color:#fffefe;'>their <span> <span style='background-color:#fff9f9;'>performances <span> <span style='background-color:#fffdfd;'>for <span> <span style='background-color:#fffdfd;'>the <span> <span style='background-color:#fffafa;'>sake <span> <span style='background-color:#fffefe;'>of <span> <span style='background-color:#fffefe;'>camera <span> <span style='background-color:#fffdfd;'>such <span> <span style='background-color:#fffafa;'>is <span> <span style='background-color:#fffafa;'>not <span> <span style='background-color:#fffdfd;'>case <span> <span style='background-color:#fffcfc;'>with <span> <span style='background-color:#fffefe;'>betsy <span> <span style='background-color:#fffdfd;'>joslyn <span> <span style='background-color:#fff7f7;'>as <span> <span style='background-color:#ffffff;'>joanna <span> <span style='background-color:#fffdfd;'>her <span> <span style='background-color:#ffffff;'>larger <span> <span style='background-color:#fffdfd;'>than <span> <span style='background-color:#fffdfd;'>life <span> <span style='background-color:#fff8f8;'>performance <span> <span style='background-color:#fffafa;'>reads <span> <span style='background-color:#ffdddd;'>unpleasantly <span> <span style='background-color:#ffdada;'>frantic <span> <span style='background-color:#ffe6e6;'>extremely <span> <span style='background-color:#fff1f1;'>operatic <span> <span style='background-color:#fff9f9;'>voice <span> <span style='background-color:#ffdcdc;'>feels <span> <span style='background-color:#fff6f6;'>out <span> <span style='background-color:#fffbfb;'>place <span> <span style='background-color:#fffbfb;'>when <span> <span style='background-color:#fff6f6;'>contrasted <span> <span style='background-color:#fffcfc;'>voices <span> <span style='background-color:#ffe5e5;'>overall <span> <span style='background-color:#fff2f2;'>cast <span> </div><br><div style='font-size: large;border-left-width:10px;border-left-style: solid; border-left-color: #ff0000'><span style='background-color:#fff7f7;'>taking <span> <span style='background-color:#ffecec;'>this <span> <span style='background-color:#ffefef;'>stage <span> <span style='background-color:#ffecec;'>play <span> <span style='background-color:#fff8f8;'>on <span> <span style='background-color:#ffdede;'>film <span> <span style='background-color:#ffefef;'>effect <span> <span style='background-color:#fff8f8;'>into <span> <span style='background-color:#fff6f6;'>consideration <span> <span style='background-color:#ffe6e6;'>however <span> <span style='background-color:#ffa5a5;'>really <span> <span style='background-color:#ffadad;'>is <span> <span style='background-color:#ffa8a8;'>an <span> <span style='background-color:#ff0000;'>exceptional <span> <span style='background-color:#ff4c4c;'>performance <span> <span style='background-color:#ffeded;'>of <span> <span style='background-color:#ffeded;'>a <span> <span style='background-color:#ffdada;'>unique <span> <span style='background-color:#ffebeb;'>and <span> <span style='background-color:#fffefe;'>macabrely <span> <span style='background-color:#ffecec;'>comic <span> <span style='background-color:#fff3f3;'>musical <span> <span style='background-color:#fff7f7;'>in <span> <span style='background-color:#fff5f5;'>the <span> <span style='background-color:#fff1f1;'>operetta <span> <span style='background-color:#ffeaea;'>style <span> </div><br><div style='font-size: large;border-left-width:10px;border-left-style: solid; border-left-color: #ff4b4b'><span style='background-color:#ffe6e6;'>lansbury <span> <span style='background-color:#ffe9e9;'>is <span> <span style='background-color:#ffb8b8;'>astonishing <span> <span style='background-color:#ffdfdf;'>a <span> <span style='background-color:#ffb7b7;'>mixture <span> <span style='background-color:#fffcfc;'>of <span> <span style='background-color:#ffc3c3;'>silliness <span> <span style='background-color:#ff9393;'>stupidity <span> <span style='background-color:#ffeded;'>and <span> <span style='background-color:#ffebeb;'>cunning <span> <span style='background-color:#ffe1e1;'>malice <span> <span style='background-color:#ffe5e5;'>while <span> <span style='background-color:#fff0f0;'>hern <span> <span style='background-color:#ffc3c3;'>truly <span> <span style='background-color:#ffdddd;'>owns <span> <span style='background-color:#fffbfb;'>the <span> <span style='background-color:#fff5f5;'>role <span> <span style='background-color:#ffe6e6;'>psychotic <span> <span style='background-color:#fffafa;'>barber <span> <span style='background-color:#fff7f7;'>whose <span> <span style='background-color:#fff6f6;'>clients <span> <span style='background-color:#fffcfc;'>go <span> <span style='background-color:#fffefe;'>to <span> <span style='background-color:#fffefe;'>their <span> <span style='background-color:#fffdfd;'>graves <span> <span style='background-color:#ffd1d1;'>impeccably <span> <span style='background-color:#fff7f7;'>shaved <span> </div><br><div style='font-size: large;border-left-width:10px;border-left-style: solid; border-left-color: #ff9393'><span style='background-color:#fffefe;'>the <span> <span style='background-color:#ffdede;'>overall <span> <span style='background-color:#ffe9e9;'>cast <span> <span style='background-color:#fff5f5;'>is <span> <span style='background-color:#fff0f0;'>quite <span> <span style='background-color:#ffd1d1;'>fine <span> <span style='background-color:#fff0f0;'>and <span> <span style='background-color:#ffe2e2;'>although <span> <span style='background-color:#ffe6e6;'>film <span> <span style='background-color:#fff1f1;'>does <span> <span style='background-color:#fff5f5;'>not <span> <span style='background-color:#fff8f8;'>let <span> <span style='background-color:#fffdfd;'>us <span> <span style='background-color:#fffdfd;'>see <span> <span style='background-color:#ffe6e6;'>enough <span> <span style='background-color:#fffdfd;'>of <span> <span style='background-color:#fffdfd;'>set <span> <span style='background-color:#fffcfc;'>there <span> <span style='background-color:#fffcfc;'>on <span> <span style='background-color:#fffdfd;'>display <span> <span style='background-color:#fffdfd;'>for <span> <span style='background-color:#fff7f7;'>it <span> <span style='background-color:#fffdfd;'>to <span> <span style='background-color:#fffcfc;'>be <span> <span style='background-color:#ffe4e4;'>impressive <span> </div><br><div style='font-size: large;border-left-width:10px;border-left-style: solid; border-left-color: #ffffff'><span style='background-color:#fff7f7;'>and <span> <span style='background-color:#fff9f9;'>the <span> <span style='background-color:#fff9f9;'>music <span> </div><br><div style='font-size: large;border-left-width:10px;border-left-style: solid; border-left-color: #fff7f7'><span style='background-color:#fffcfc;'>who <span> <span style='background-color:#fffbfb;'>can <span> <span style='background-color:#fff9f9;'>argue <span> <span style='background-color:#fffdfd;'>with <span> <span style='background-color:#fffcfc;'>what <span> <span style='background-color:#ffefef;'>most <span> <span style='background-color:#fff6f6;'>consider <span> <span style='background-color:#ffffff;'>sondheim's <span> <span style='background-color:#fff7f7;'>finest <span> <span style='background-color:#fff8f8;'>work <span> </div><br><div style='font-size: large;border-left-width:10px;border-left-style: solid; border-left-color: #ff7575'><span style='background-color:#fff8f8;'>the <span> <span style='background-color:#fff3f3;'>story <span> <span style='background-color:#ffe3e3;'>itself <span> <span style='background-color:#ffc5c5;'>is <span> <span style='background-color:#ff2121;'>extremely <span> <span style='background-color:#ff8c8c;'>well <span> <span style='background-color:#ffd7d7;'>known <span> <span style='background-color:#ffb1b1;'>particularly <span> <span style='background-color:#fff1f1;'>in <span> <span style='background-color:#fffafa;'>england <span> </div><br><div style='font-size: large;border-left-width:10px;border-left-style: solid; border-left-color: #ffecec'><span style='background-color:#ffffff;'>in <span> <span style='background-color:#ffffff;'>1846 <span> <span style='background-color:#ffffff;'>thomas <span> <span style='background-color:#ffffff;'>peckett <span> <span style='background-color:#ffffff;'>prest <span> <span style='background-color:#fffafa;'>cobbled <span> <span style='background-color:#fffcfc;'>together <span> <span style='background-color:#fffdfd;'>several <span> <span style='background-color:#fffefe;'>urban <span> <span style='background-color:#fffefe;'>myths <span> <span style='background-color:#fffefe;'>for <span> <span style='background-color:#fffefe;'>a <span> <span style='background-color:#fffdfd;'>short <span> <span style='background-color:#fffdfd;'>story <span> <span style='background-color:#fffdfd;'>he <span> <span style='background-color:#ffffff;'>titled <span> <span style='background-color:#fffcfc;'>string <span> <span style='background-color:#ffffff;'>of <span> <span style='background-color:#fffbfb;'>pearls <span> <span style='background-color:#fffefe;'>within <span> <span style='background-color:#fffefe;'>year <span> <span style='background-color:#ffffff;'>or <span> <span style='background-color:#fffcfc;'>so <span> <span style='background-color:#fffbfb;'>it <span> <span style='background-color:#fffbfb;'>was <span> <span style='background-color:#fffcfc;'>adapted <span> <span style='background-color:#fffdfd;'>to <span> <span style='background-color:#ffffff;'>the <span> <span style='background-color:#fffefe;'>stage <span> <span style='background-color:#fffefe;'>as <span> <span style='background-color:#fffefe;'>sweeney <span> <span style='background-color:#ffffff;'>todd <span> <span style='background-color:#fffdfd;'>demon <span> <span style='background-color:#fffefe;'>barber <span> <span style='background-color:#fffefe;'>fleet <span> <span style='background-color:#ffffff;'>street <span> <span style='background-color:#ffffff;'>and <span> <span style='background-color:#fffefe;'>an <span> <span style='background-color:#fffdfd;'>era <span> <span style='background-color:#fffcfc;'>that <span> <span style='background-color:#fffafa;'>knew <span> <span style='background-color:#fffdfd;'>little <span> <span style='background-color:#ffffff;'>copyright <span> <span style='background-color:#ffffff;'>law <span> <span style='background-color:#fffefe;'>variations <span> <span style='background-color:#fffefe;'>play <span> <span style='background-color:#fffefe;'>were <span> <span style='background-color:#fffefe;'>soon <span> <span style='background-color:#fffdfd;'>playing <span> <span style='background-color:#fffdfd;'>all <span> <span style='background-color:#fffefe;'>over <span> <span style='background-color:#ffffff;'>england <span> </div><br><div style='font-size: large;border-left-width:10px;border-left-style: solid; border-left-color: #fff5f5'><span style='background-color:#fffefe;'>each <span> <span style='background-color:#fffdfd;'>one <span> <span style='background-color:#fff9f9;'>however <span> <span style='background-color:#fff9f9;'>was <span> <span style='background-color:#fffdfd;'>more <span> <span style='background-color:#fffefe;'>or <span> <span style='background-color:#fffefe;'>less <span> <span style='background-color:#fffefe;'>the <span> <span style='background-color:#fffefe;'>same <span> <span style='background-color:#ffffff;'>sweeney <span> <span style='background-color:#ffffff;'>todd <span> <span style='background-color:#ffffff;'>a <span> <span style='background-color:#ffffff;'>barber <span> <span style='background-color:#fffcfc;'>kills <span> <span style='background-color:#ffffff;'>men <span> <span style='background-color:#ffffff;'>who <span> <span style='background-color:#ffffff;'>come <span> <span style='background-color:#ffffff;'>to <span> <span style='background-color:#ffffff;'>him <span> <span style='background-color:#ffffff;'>for <span> <span style='background-color:#fffdfd;'>shave <span> <span style='background-color:#fffefe;'>mrs <span> <span style='background-color:#fffefe;'>lovett <span> <span style='background-color:#fffefe;'>his <span> <span style='background-color:#fffdfd;'>associate <span> <span style='background-color:#fff7f7;'>bakes <span> <span style='background-color:#fffefe;'>them <span> <span style='background-color:#fffefe;'>up <span> <span style='background-color:#ffffff;'>into <span> <span style='background-color:#fffefe;'>pies <span> <span style='background-color:#fffefe;'>and <span> <span style='background-color:#fffdfd;'>feeds <span> <span style='background-color:#fffefe;'>an <span> <span style='background-color:#fffcfc;'>unsuspecting <span> <span style='background-color:#ffffff;'>public <span> </div><br><div style='font-size: large;border-left-width:10px;border-left-style: solid; border-left-color: #ffeded'><span style='background-color:#fff9f9;'>the <span> <span style='background-color:#fff7f7;'>sondheim <span> <span style='background-color:#fffafa;'>version <span> <span style='background-color:#ffeaea;'>is <span> <span style='background-color:#ffeeee;'>specifically <span> <span style='background-color:#fff6f6;'>based <span> <span style='background-color:#fffcfc;'>on <span> <span style='background-color:#fffbfb;'>a <span> <span style='background-color:#fffdfd;'>1973 <span> <span style='background-color:#fffdfd;'>by <span> <span style='background-color:#fffcfc;'>christopher <span> <span style='background-color:#fffbfb;'>bond <span> </div><br><div style='font-size: large;border-left-width:10px;border-left-style: solid; border-left-color: #ffc9c9'><span style='background-color:#fffefe;'>the <span> <span style='background-color:#fffcfc;'>story <span> <span style='background-color:#fff6f6;'>is <span> <span style='background-color:#ffe1e1;'>very <span> <span style='background-color:#fff8f8;'>grand <span> <span style='background-color:#fffcfc;'>guignol <span> <span style='background-color:#fffefe;'>with <span> <span style='background-color:#fffcfc;'>a <span> <span style='background-color:#fff5f5;'>lot <span> <span style='background-color:#fffdfd;'>of <span> <span style='background-color:#fffdfd;'>blood <span> <span style='background-color:#fffefe;'>bodies <span> <span style='background-color:#fffafa;'>dropping <span> <span style='background-color:#fffafa;'>down <span> <span style='background-color:#fffdfd;'>chutes <span> <span style='background-color:#fffafa;'>and <span> <span style='background-color:#fff1f1;'>grotesque <span> <span style='background-color:#fff4f4;'>humor <span> <span style='background-color:#fffdfd;'>at <span> <span style='background-color:#fffcfc;'>same <span> <span style='background-color:#fffbfb;'>time <span> <span style='background-color:#fff8f8;'>however <span> <span style='background-color:#fffdfd;'>music <span> <span style='background-color:#fffbfb;'>lyrics <span> <span style='background-color:#ffe4e4;'>subplot <span> <span style='background-color:#fff9f9;'>an <span> <span style='background-color:#fffcfc;'>innocent <span> <span style='background-color:#fffdfd;'>in <span> <span style='background-color:#fff8f8;'>clutches <span> <span style='background-color:#fffbfb;'>evil <span> <span style='background-color:#fffefe;'>open <span> <span style='background-color:#fffefe;'>out <span> <span style='background-color:#ffffff;'>subject <span> <span style='background-color:#ffffff;'>to <span> <span style='background-color:#fffefe;'>numerous <span> <span style='background-color:#fffdfd;'>lyric <span> <span style='background-color:#fffcfc;'>charms <span> <span style='background-color:#fffafa;'>one <span> <span style='background-color:#fffbfb;'>would <span> <span style='background-color:#fffbfb;'>not <span> <span style='background-color:#fff8f8;'>expect <span> </div><br><div style='font-size: large;border-left-width:10px;border-left-style: solid; border-left-color: #ffaeae'><span style='background-color:#ffffff;'>sondheim's <span> <span style='background-color:#ffffff;'>lyrics <span> <span style='background-color:#fffdfd;'>are <span> <span style='background-color:#fff8f8;'>often <span> <span style='background-color:#ffe8e8;'>ironic <span> <span style='background-color:#ffefef;'>but <span> <span style='background-color:#fff0f0;'>never <span> <span style='background-color:#fffcfc;'>more <span> <span style='background-color:#fff9f9;'>so <span> <span style='background-color:#fffcfc;'>than <span> <span style='background-color:#fffefe;'>here <span> <span style='background-color:#fffdfd;'>he <span> <span style='background-color:#fff9f9;'>intertwines <span> <span style='background-color:#fff9f9;'>a <span> <span style='background-color:#ffe2e2;'>great <span> <span style='background-color:#ffebeb;'>deal <span> <span style='background-color:#fffcfc;'>of <span> <span style='background-color:#ffeaea;'>wicked <span> <span style='background-color:#ffe3e3;'>satire <span> <span style='background-color:#fff5f5;'>re <span> <span style='background-color:#ffeded;'>industry <span> <span style='background-color:#fffdfd;'>and <span> <span style='background-color:#fff9f9;'>capitalism <span> <span style='background-color:#fffcfc;'>along <span> <span style='background-color:#fffdfd;'>the <span> <span style='background-color:#fffbfb;'>way <span> <span style='background-color:#fff3f3;'>certainly <span> <span style='background-color:#fff8f8;'>one <span> <span style='background-color:#fff8f8;'>cannot <span> <span style='background-color:#ffecec;'>fault <span> <span style='background-color:#fff9f9;'>strange <span> <span style='background-color:#fff7f7;'>yet <span> <span style='background-color:#fffcfc;'>victorian <span> <span style='background-color:#fff4f4;'>elegant <span> <span style='background-color:#fffcfc;'>his <span> <span style='background-color:#fff1f1;'>complex <span> <span style='background-color:#fffbfb;'>music <span> </div><br><div style='font-size: large;border-left-width:10px;border-left-style: solid; border-left-color: #ff8f8f'><span style='background-color:#fff7f7;'>like <span> <span style='background-color:#fffafa;'>the <span> <span style='background-color:#fffafa;'>concert <span> <span style='background-color:#fff5f5;'>version <span> <span style='background-color:#fff3f3;'>starring <span> <span style='background-color:#fff8f8;'>hern <span> <span style='background-color:#fffafa;'>and <span> <span style='background-color:#fffbfb;'>patti <span> <span style='background-color:#fff9f9;'>lupone <span> <span style='background-color:#fff7f7;'>this <span> <span style='background-color:#fff1f1;'>particular <span> <span style='background-color:#ffefef;'>film <span> <span style='background-color:#ffe2e2;'>also <span> <span style='background-color:#ffd5d5;'>provides <span> <span style='background-color:#fff1f1;'>us <span> <span style='background-color:#fff9f9;'>with <span> <span style='background-color:#fff9f9;'>several <span> <span style='background-color:#fff7f7;'>selections <span> <span style='background-color:#fff8f8;'>that <span> <span style='background-color:#fff9f9;'>were <span> <span style='background-color:#fff4f4;'>cut <span> <span style='background-color:#fffcfc;'>from <span> <span style='background-color:#fffefe;'>2007 <span> <span style='background-color:#fffdfd;'>tim <span> <span style='background-color:#fffcfc;'>burton <span> <span style='background-color:#ffd9d9;'>most <span> <span style='background-color:#ffd6d6;'>particularly <span> <span style='background-color:#fff4f4;'>opening <span> <span style='background-color:#fffcfc;'>attend <span> <span style='background-color:#fff8f8;'>tale <span> <span style='background-color:#fffcfc;'>of <span> <span style='background-color:#fffcfc;'>sweeney <span> <span style='background-color:#fffdfd;'>todd <span> <span style='background-color:#fff9f9;'>which <span> <span style='background-color:#fff2f2;'>runs <span> <span style='background-color:#fffafa;'>a <span> <span style='background-color:#fff7f7;'>thread <span> <span style='background-color:#fff3f3;'>throughout <span> <span style='background-color:#fff8f8;'>play <span> </div><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels = ['negative', 'positive']\n",
    "label_probs = dict(zip(labels, pred))\n",
    "\n",
    "visualize_attention(word_att, sent_att, sent_tokenized_review, label_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv_38",
   "language": "python",
   "name": "myenv_38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
